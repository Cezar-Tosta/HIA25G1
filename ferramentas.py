import os
import pandas as pd
import json
from pathlib import Path
from typing import List, Dict, Any, Optional
import re

# Processamento de arquivos
import PyPDF2
import pdfplumber
from docx import Document as DocxDocument
import openpyxl

# RAG
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.docstore.document import Document

# Visualiza√ß√µes
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from io import BytesIO
import base64

# CrewAI
from crewai.tools import tool
from dotenv import load_dotenv

load_dotenv()

# ============================================================================
# FERRAMENTA 1: LEITOR UNIVERSAL DE DOCUMENTOS (PDF/WORD/EXCEL)
# ============================================================================

class DocumentReader:
    """Leitor universal de documentos com busca sem√¢ntica"""
    
    def __init__(self, docs_directory: str = "./documentos"):
        self.docs_directory = Path(docs_directory)
        self.vector_store = None
        self.documents_metadata = {}
        self._initialize()
    
    def _initialize(self):
        """Indexa todos os documentos"""
        
        if not self.docs_directory.exists():
            self.docs_directory.mkdir(parents=True, exist_ok=True)
            print(f"[Doc Reader] Diret√≥rio criado: {self.docs_directory}")
            return
        
        all_documents = []
        
        # PDFs
        for pdf_file in self.docs_directory.glob("*.pdf"):
            try:
                docs = self._extract_from_pdf(pdf_file)
                all_documents.extend(docs)
                self.documents_metadata[pdf_file.name] = {
                    'type': 'pdf',
                    'chunks': len(docs),
                    'processed': True
                }
                print(f"[Doc Reader] ‚úÖ PDF processado: {pdf_file.name}")
            except Exception as e:
                print(f"[Doc Reader] ‚ùå Erro em {pdf_file.name}: {e}")
        
        # Word
        for word_file in self.docs_directory.glob("*.docx"):
            try:
                docs = self._extract_from_word(word_file)
                all_documents.extend(docs)
                self.documents_metadata[word_file.name] = {
                    'type': 'word',
                    'chunks': len(docs),
                    'processed': True
                }
                print(f"[Doc Reader] ‚úÖ Word processado: {word_file.name}")
            except Exception as e:
                print(f"[Doc Reader] ‚ùå Erro em {word_file.name}: {e}")
        
        # Excel
        for excel_file in self.docs_directory.glob("*.xlsx"):
            try:
                docs = self._extract_from_excel(excel_file)
                all_documents.extend(docs)
                self.documents_metadata[excel_file.name] = {
                    'type': 'excel',
                    'chunks': len(docs),
                    'processed': True
                }
                print(f"[Doc Reader] ‚úÖ Excel processado: {excel_file.name}")
            except Exception as e:
                print(f"[Doc Reader] ‚ùå Erro em {excel_file.name}: {e}")
        
        if all_documents:
            embeddings = OpenAIEmbeddings(api_key=os.getenv('OPENAI_API_KEY'))
            self.vector_store = FAISS.from_documents(all_documents, embeddings)
            print(f"[Doc Reader] üéâ Indexados {len(all_documents)} chunks de {len(self.documents_metadata)} documentos")
    
    def _extract_from_pdf(self, pdf_path: Path) -> List[Document]:
        """Extrai texto de PDF"""
        full_text = ""
        
        with pdfplumber.open(pdf_path) as pdf:
            for page_num, page in enumerate(pdf.pages, start=1):
                text = page.extract_text()
                if text:
                    full_text += f"\n--- P√°gina {page_num} ---\n{text}"
        
        return self._chunk_text(full_text, pdf_path.name)
    
    def _extract_from_word(self, word_path: Path) -> List[Document]:
        """Extrai texto de Word"""
        doc = DocxDocument(word_path)
        full_text = "\n".join([para.text for para in doc.paragraphs if para.text.strip()])
        
        return self._chunk_text(full_text, word_path.name)
    
    def _extract_from_excel(self, excel_path: Path) -> List[Document]:
        """Extrai dados de Excel"""
        wb = openpyxl.load_workbook(excel_path)
        full_text = ""
        
        for sheet_name in wb.sheetnames:
            ws = wb[sheet_name]
            full_text += f"\n\n=== Planilha: {sheet_name} ===\n\n"
            
            for row in ws.iter_rows(values_only=True):
                row_text = " | ".join([str(cell) if cell else "" for cell in row])
                if row_text.strip():
                    full_text += row_text + "\n"
        
        return self._chunk_text(full_text, excel_path.name)
    
    def _chunk_text(self, text: str, source: str) -> List[Document]:
        """Divide texto em chunks"""
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        chunks = splitter.split_text(text)
        
        return [
            Document(
                page_content=chunk,
                metadata={'source': source, 'chunk_id': i}
            )
            for i, chunk in enumerate(chunks)
        ]
    
    def search(self, query: str, k: int = 3) -> str:
        """Busca informa√ß√µes nos documentos"""
        
        if not self.vector_store:
            return "‚ùå Nenhum documento indexado. Adicione arquivos em ./documentos/"
        
        docs = self.vector_store.similarity_search(query, k=k)
        
        if not docs:
            return f"‚ùå Nenhuma informa√ß√£o encontrada sobre: {query}"
        
        response = f"üìö INFORMA√á√ïES DOS DOCUMENTOS:\n\n"
        for i, doc in enumerate(docs, 1):
            source = doc.metadata.get('source', 'Desconhecido')
            response += f"[{i}] üìÑ {source}\n"
            response += f"{doc.page_content}\n"
            response += "-" * 80 + "\n\n"
        
        return response


# ============================================================================
# FERRAMENTA 2: ANALISADOR DE CSV E BANCO LOCAL
# ============================================================================

class CSVDatabaseAnalyzer:
    """Analisador de dados CSV como banco de dados local"""
    
    def __init__(self, csv_directory: str = "./dados"):
        self.csv_directory = Path(csv_directory)
        self.dataframes = {}
        self._load_csvs()
    
    def _load_csvs(self):
        """Carrega todos os CSVs"""
        
        if not self.csv_directory.exists():
            self.csv_directory.mkdir(parents=True, exist_ok=True)
            print(f"[CSV Analyzer] Diret√≥rio criado: {self.csv_directory}")
            return
        
        for csv_file in self.csv_directory.glob("*.csv"):
            try:
                df = pd.read_csv(csv_file)
                table_name = csv_file.stem
                self.dataframes[table_name] = df
                print(f"[CSV Analyzer] ‚úÖ Carregado: {table_name} ({len(df)} linhas)")
            except Exception as e:
                print(f"[CSV Analyzer] ‚ùå Erro em {csv_file.name}: {e}")
    
    def query(self, question: str) -> str:
        """Responde perguntas sobre os dados"""
        
        if not self.dataframes:
            return "‚ùå Nenhum arquivo CSV encontrado em ./dados/"
        
        # Listar tabelas dispon√≠veis
        tables_info = "\n".join([
            f"- {name}: {len(df)} linhas, {len(df.columns)} colunas"
            for name, df in self.dataframes.items()
        ])
        
        response = f"üìä DADOS DISPON√çVEIS:\n{tables_info}\n\n"
        
        # An√°lise simples baseada em palavras-chave
        question_lower = question.lower()
        
        # Exemplo: "quantos pacientes"
        if "pacientes" in question_lower and "quantos" in question_lower:
            if "pacientes" in self.dataframes:
                total = len(self.dataframes["pacientes"])
                response += f"Total de pacientes: {total}\n"
        
        # Exemplo: "m√©dia de idade"
        if "m√©dia" in question_lower or "media" in question_lower:
            if "pacientes" in self.dataframes:
                df = self.dataframes["pacientes"]
                if "idade" in df.columns:
                    media = df["idade"].mean()
                    response += f"M√©dia de idade: {media:.1f} anos\n"
        
        # Exemplo: "total de consultas"
        if "consultas" in question_lower and "total" in question_lower:
            if "consultas" in self.dataframes:
                total = len(self.dataframes["consultas"])
                response += f"Total de consultas: {total}\n"
        
        # Estat√≠sticas gerais
        response += "\nüìà ESTAT√çSTICAS:\n"
        for name, df in self.dataframes.items():
            response += f"\n{name.upper()}:\n"
            response += f"  Registros: {len(df)}\n"
            response += f"  Colunas: {', '.join(df.columns.tolist()[:5])}\n"
            
            # Mostrar primeiras linhas
            response += f"\nPrimeiras linhas de {name}:\n"
            response += df.head(3).to_string(index=False) + "\n"
        
        return response
    
    def get_statistics(self, table_name: str) -> str:
        """Retorna estat√≠sticas de uma tabela"""
        
        if table_name not in self.dataframes:
            available = ", ".join(self.dataframes.keys())
            return f"‚ùå Tabela '{table_name}' n√£o encontrada. Dispon√≠veis: {available}"
        
        df = self.dataframes[table_name]
        
        response = f"üìä ESTAT√çSTICAS: {table_name}\n\n"
        response += f"Total de registros: {len(df)}\n"
        response += f"Colunas: {len(df.columns)}\n\n"
        
        # Estat√≠sticas num√©ricas
        numeric_cols = df.select_dtypes(include=['number']).columns
        if len(numeric_cols) > 0:
            response += "COLUNAS NUM√âRICAS:\n"
            response += df[numeric_cols].describe().to_string() + "\n\n"
        
        # Valores √∫nicos
        response += "VALORES √öNICOS:\n"
        for col in df.columns[:5]:
            unique = df[col].nunique()
            response += f"  {col}: {unique} valores √∫nicos\n"
        
        return response


# ============================================================================
# FERRAMENTA 3: GERADOR DE VISUALIZA√á√ïES
# ============================================================================

class VisualizationGenerator:
    """Gera gr√°ficos e visualiza√ß√µes"""
    
    def __init__(self, output_dir: str = "./visualizacoes"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
    
    def create_chart(self, data_dict: Dict[str, Any], chart_type: str = "bar") -> str:
        """Cria gr√°fico e retorna path"""
        
        try:
            # Dados de exemplo se n√£o fornecidos
            if not data_dict:
                data_dict = {
                    'labels': ['Jan', 'Fev', 'Mar', 'Abr', 'Mai'],
                    'values': [65, 72, 68, 75, 70]
                }
            
            labels = data_dict.get('labels', [])
            values = data_dict.get('values', [])
            
            # Criar figura
            fig = go.Figure()
            
            if chart_type == "bar":
                fig.add_trace(go.Bar(x=labels, y=values))
            elif chart_type == "line":
                fig.add_trace(go.Scatter(x=labels, y=values, mode='lines+markers'))
            elif chart_type == "pie":
                fig.add_trace(go.Pie(labels=labels, values=values))
            
            fig.update_layout(
                title=data_dict.get('title', 'Gr√°fico'),
                template='plotly_white'
            )
            
            # Salvar
            filename = f"chart_{chart_type}_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.html"
            filepath = self.output_dir / filename
            fig.write_html(str(filepath))
            
            return f"‚úÖ Gr√°fico criado: {filepath}\nAcesse o arquivo para visualizar."
            
        except Exception as e:
            return f"‚ùå Erro ao criar gr√°fico: {str(e)}"


# ============================================================================
# FERRAMENTA 4: BUSCADOR WEB PARA GUIDELINES M√âDICAS
# ============================================================================

@tool("buscar_guidelines_medicas")
def buscar_guidelines_medicas(query: str) -> str:
    """
    Busca guidelines e protocolos m√©dicos na web.
    √ötil para encontrar diretrizes cl√≠nicas, protocolos de tratamento,
    recomenda√ß√µes de sociedades m√©dicas, etc.
    
    Args:
        query: Termo de busca (ex: "protocolo diabetes tipo 2")
        
    Returns:
        Informa√ß√µes relevantes de fontes m√©dicas confi√°veis
    """
    
    # Simula√ß√£o - em produ√ß√£o, integraria com APIs reais
    guidelines = {
        "diabetes": "Diretrizes SBD 2024: HbA1c alvo <7%, monitoramento trimestral, metformina primeira linha.",
        "hipertens√£o": "Diretriz Brasileira 2020: PA alvo <140/90mmHg, IECA/BRA primeira escolha.",
        "covid": "Protocolo MS 2024: Isolamento 5 dias, sintom√°ticos tratamento suportivo.",
    }
    
    query_lower = query.lower()
    
    response = "üîç GUIDELINES M√âDICAS:\n\n"
    
    found = False
    for key, value in guidelines.items():
        if key in query_lower:
            response += f"üìã {key.upper()}:\n{value}\n\n"
            found = True
    
    if not found:
        response += f"‚ö†Ô∏è Nenhuma guideline espec√≠fica encontrada para '{query}'.\n"
        response += "Recomendo consultar:\n"
        response += "- Sociedade Brasileira de Medicina\n"
        response += "- Minist√©rio da Sa√∫de\n"
        response += "- UpToDate / DynaMed\n"
    
    response += "\n‚ö†Ô∏è IMPORTANTE: Sempre verificar fontes prim√°rias e validade das diretrizes."
    
    return response


# ============================================================================
# INSTANCIAR FERRAMENTAS
# ============================================================================

doc_reader = DocumentReader()
csv_analyzer = CSVDatabaseAnalyzer()
viz_generator = VisualizationGenerator()


# ============================================================================
# DECORATORS PARA CREWAI
# ============================================================================

@tool("ler_documentos")
def ler_documentos(pergunta: str) -> str:
    """
    Busca informa√ß√µes em documentos (PDF, Word, Excel).
    Use para encontrar protocolos, relat√≥rios, diretrizes documentadas.
    
    Args:
        pergunta: O que voc√™ quer saber dos documentos
        
    Returns:
        Informa√ß√µes encontradas com fonte
    """
    return doc_reader.search(pergunta)


@tool("consultar_banco_dados")
def consultar_banco_dados(pergunta: str) -> str:
    """
    Consulta dados em arquivos CSV (pacientes, consultas, custos, etc).
    Use para an√°lises quantitativas, estat√≠sticas, contagens.
    
    Args:
        pergunta: Pergunta sobre os dados (ex: "quantos pacientes diab√©ticos?")
        
    Returns:
        An√°lise dos dados com n√∫meros e estat√≠sticas
    """
    return csv_analyzer.query(pergunta)


@tool("gerar_visualizacao")
def gerar_visualizacao(descricao: str) -> str:
    """
    Cria gr√°ficos e visualiza√ß√µes.
    Use quando precisar ilustrar dados visualmente.
    
    Args:
        descricao: Tipo de gr√°fico e dados (ex: "gr√°fico de barras com consultas por m√™s")
        
    Returns:
        Path do arquivo gerado
    """
    # Exemplo simples - em produ√ß√£o, parsearia a descri√ß√£o
    return viz_generator.create_chart({}, "bar")