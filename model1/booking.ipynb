{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66962e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# --- Configuração ---\n",
    "# Altere esta variável para o caminho da sua pasta 'data'\n",
    "caminho_para_pasta = './data/' # '.' significa o diretório atual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4caef004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando carregamento de tabelas particionadas ---\n",
      "DataFrame 'marcacao' carregado com 3,122,088 linhas a partir de 57 arquivos.\n",
      "DataFrame 'oferta_programada' carregado com 9,200,972 linhas a partir de 24 arquivos.\n",
      "DataFrame 'profissional_historico' carregado com 5,064,858 linhas a partir de 18 arquivos.\n",
      "DataFrame 'solicitacao' carregado com 3,210,746 linhas a partir de 40 arquivos.\n",
      "\n",
      "--- Iniciando carregamento de tabelas únicas ---\n",
      "DataFrame 'cids' carregado com 12,454 linhas.\n",
      "DataFrame 'equipamento_historico' carregado com 194,228 linhas.\n",
      "DataFrame 'habilitacao_historico' carregado com 21,166 linhas.\n",
      "DataFrame 'leito_historico' carregado com 27,795 linhas.\n",
      "DataFrame 'procedimento' carregado com 806 linhas.\n",
      "DataFrame 'tempo_espera' carregado com 70,104 linhas.\n",
      "DataFrame 'unidade_historico' carregado com 25,026 linhas.\n",
      "\n",
      "--- Carregamento Concluído! ---\n",
      "\n",
      "Exemplo: 5 primeiras linhas do DataFrame 'marcacao':\n",
      "                         profissional_solicitante_id  \\\n",
      "0  a3d4f399a0cce984fdfe528276fdf7dae9996caf535da1...   \n",
      "1  c1c30ec8c3e044b864733e3a43aaaecababa3ee086a94c...   \n",
      "2  c1c30ec8c3e044b864733e3a43aaaecababa3ee086a94c...   \n",
      "3  b96c378af0f437ee15bf57a642f388dde3619b0a8594c8...   \n",
      "4  b96c378af0f437ee15bf57a642f388dde3619b0a8594c8...   \n",
      "\n",
      "                          profissional_executante_id  \\\n",
      "0  f847da2c73e419e7ae340b5140397c7a0ff01956745e75...   \n",
      "1  162cb46c37e32d8707cf91309107fe18b1109c329ff9e3...   \n",
      "2  0f2f14b1be912352487f8fbe58ab6399e515ef958b392a...   \n",
      "3  31cd99ec20cb6652ba54cad2bbbc8d8fbf1cb879ccc780...   \n",
      "4  fc243e7402e075394dd4bcb71a20f9394f143ee71bdd83...   \n",
      "\n",
      "                             operador_solicitante_id  \\\n",
      "0  1938ecf707574c86bd9fb213b12ac158e9c9a384feaea8...   \n",
      "1  5ea0742d02d8d2ff7bacbb91638793ff8d7b09a031ceff...   \n",
      "2  5ea0742d02d8d2ff7bacbb91638793ff8d7b09a031ceff...   \n",
      "3  766fc1a5356cccf0cc9f56ce8d2d6b43fce3a1d945d3a7...   \n",
      "4  766fc1a5356cccf0cc9f56ce8d2d6b43fce3a1d945d3a7...   \n",
      "\n",
      "                             operador_autorizador_id operador_cancelamento_id  \\\n",
      "0  000d5a386364c1264fffcfff426b0f2c9aa10ff532296c...                     None   \n",
      "1  000d5a386364c1264fffcfff426b0f2c9aa10ff532296c...                     None   \n",
      "2  000d5a386364c1264fffcfff426b0f2c9aa10ff532296c...                     None   \n",
      "3  0033cc1c3147ad89d80de49d8fb4f1aa5298791a247332...                     None   \n",
      "4  0033cc1c3147ad89d80de49d8fb4f1aa5298791a247332...                     None   \n",
      "\n",
      "  operador_videofonista_id central_solicitante central_reguladora  \\\n",
      "0                     None      RIO DE JANEIRO     RIO DE JANEIRO   \n",
      "1                     None      RIO DE JANEIRO     RIO DE JANEIRO   \n",
      "2                     None      RIO DE JANEIRO     RIO DE JANEIRO   \n",
      "3                     None      RIO DE JANEIRO     RIO DE JANEIRO   \n",
      "4                     None      RIO DE JANEIRO     RIO DE JANEIRO   \n",
      "\n",
      "  unidade_solicitante_id_cnes unidade_desejada_id_cnes  ...  \\\n",
      "0                     7108265                     None  ...   \n",
      "1                     7108265                     None  ...   \n",
      "2                     7108265                     None  ...   \n",
      "3                     2269554                     None  ...   \n",
      "4                     2269554                     None  ...   \n",
      "\n",
      "  marcacao_executada falta_registrada procedimento_sisreg_id  \\\n",
      "0                  1             None                0705343   \n",
      "1                  1             None                2300025   \n",
      "2                  1             None                0701225   \n",
      "3                  1             None                0710012   \n",
      "4                  1             None                0701225   \n",
      "\n",
      "  vaga_solicitada_tp vaga_consumida_tp cid_solicitado_id cid_agendado_id  \\\n",
      "0              1 VEZ   RESERVA TECNICA               H25             H25   \n",
      "1              1 VEZ   RESERVA TECNICA               R52             R52   \n",
      "2              1 VEZ   RESERVA TECNICA              E119            E119   \n",
      "3              1 VEZ   RESERVA TECNICA              D259            D259   \n",
      "4              1 VEZ   RESERVA TECNICA              E119            E119   \n",
      "\n",
      "  laudo_descricao_tp laudo_situacao      laudo_data_observacao  \n",
      "0         Observacão       PENDENTE 2024-08-03 09:15:28.975954  \n",
      "1         Observacão       PENDENTE 2024-06-10 18:05:37.090578  \n",
      "2         Observacão       PENDENTE 2024-05-08 09:50:58.529742  \n",
      "3      Justificativa       PENDENTE 2022-04-04 10:59:45.538848  \n",
      "4      Justificativa       PENDENTE 2023-08-07 08:22:46.596443  \n",
      "\n",
      "[5 rows x 37 columns]\n",
      "DataFrame 'marcacao' carregado com 3,122,088 linhas a partir de 57 arquivos.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from dataload import carregar_dataframe_particionado\n",
    "\n",
    "\n",
    "dfMarcacao = carregar_dataframe_particionado(caminho_para_pasta, 'marcacao')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c960ce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMarcacao.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9a39cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "condicao_absenteismo = (dfMarcacao['marcacao_executada'] == False) | (dfMarcacao['falta_registrada'] == True)\n",
    "dfMarcacao['alvo_absenteismo'] = condicao_absenteismo.astype(int)\n",
    "\n",
    "# --- Verificação ---\n",
    "print(\"Criação da variável alvo concluída!\")\n",
    "print(f\"Total de agendamentos relevantes para análise: {len(dfMarcacao):,}\")\n",
    "\n",
    "print(\"\\nDistribuição da variável alvo (alvo_absenteismo):\")\n",
    "# value_counts() mostra quantos 0s (Compareceu) e 1s (Faltou) temos.\n",
    "print(dfMarcacao['alvo_absenteismo'].value_counts())\n",
    "\n",
    "print(\"\\nExemplo de linhas do DataFrame final:\")\n",
    "# Mostra a nova coluna junto com as colunas que a originaram\n",
    "print(dfMarcacao[['data_marcacao', 'solicitacao_status', 'marcacao_executada', 'falta_registrada', 'alvo_absenteismo']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f26943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dfMarcacao['data_solicitacao'] = pd.to_datetime(dfMarcacao['data_solicitacao'], errors='coerce')\n",
    "dfMarcacao['data_marcacao'] = pd.to_datetime(dfMarcacao['data_marcacao'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423252d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Lead Time (Tempo de Espera em dias)\n",
    "dfMarcacao['lead_time_dias'] = (dfMarcacao['data_marcacao'] - dfMarcacao['data_solicitacao']).dt.days\n",
    "# Tratar casos onde a data de solicitação pode ser posterior à marcação (dados sujos)\n",
    "dfMarcacao['lead_time_dias'] = dfMarcacao['lead_time_dias'].clip(lower=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d883a9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Dia da Semana (0=Segunda, 1=Terça, ..., 6=Domingo)\n",
    "dfMarcacao['dia_semana'] = dfMarcacao['data_marcacao'].dt.dayofweek\n",
    "\n",
    "# 3. Hora do Dia\n",
    "dfMarcacao['hora_dia'] = dfMarcacao['data_marcacao'].dt.hour\n",
    "\n",
    "# 4. Mês\n",
    "dfMarcacao['mes'] = dfMarcacao['data_marcacao'].dt.month\n",
    "\n",
    "print(\"Atributos temporais criados: 'lead_time_dias', 'dia_semana', 'hora_dia', 'mes'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3355c9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeiro, ordenamos o dataframe por paciente e data. É CRUCIAL.\n",
    "dfMarcacao = dfMarcacao.sort_values(by=['paciente_id', 'data_marcacao'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d47a046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos o número de agendamentos e faltas anteriores\n",
    "# groupby().cumsum() calcula a soma cumulativa dentro de cada grupo (paciente)\n",
    "# .shift(1) desloca os dados para que cada linha veja o total ANTES de si mesma\n",
    "grouped = dfMarcacao.groupby('paciente_id')\n",
    "dfMarcacao['num_agendamentos_anteriores'] = grouped.cumcount()\n",
    "dfMarcacao['num_faltas_anteriores'] = grouped['alvo_absenteismo'].cumsum().shift(1).fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4b2ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Taxa de Absenteísmo Histórica\n",
    "# Usamos np.where para evitar divisão por zero para pacientes em seu primeiro agendamento\n",
    "dfMarcacao['taxa_absenteismo_anterior'] = np.where(\n",
    "    dfMarcacao['num_agendamentos_anteriores'] > 0,\n",
    "    dfMarcacao['num_faltas_anteriores'] / dfMarcacao['num_agendamentos_anteriores'],\n",
    "    0  # Se não há agendamentos anteriores, a taxa é 0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7ba30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- C. Fatores Geográficos e de Distância ---\n",
    "print(\"\\n--- Iniciando Engenharia de Atributos Geográficos (C) ---\")\n",
    "dfUnidadeHistorico = carregar_dataframe_particionado(caminho_para_pasta, 'unidade_historico')\n",
    "# Supondo que dfUnidadeHistorico está carregado\n",
    "# Como a tabela de unidades é histórica, vamos pegar a informação mais recente para cada CNES\n",
    "unidades = dfUnidadeHistorico.sort_values(['ano', 'mes'], ascending=False).drop_duplicates('unidade_id_cnes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4930b6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Join para obter dados da unidade SOLICITANTE\n",
    "dfMarcacao = pd.merge(\n",
    "    dfMarcacao,\n",
    "    unidades[['unidade_id_cnes', 'unidade_bairro', 'unidade_latitude', 'unidade_longitude']],\n",
    "    left_on='unidade_solicitante_id_cnes',\n",
    "    right_on='unidade_id_cnes',\n",
    "    how='left',\n",
    "    suffixes=('', '_solicitante')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51de7656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Join para obter dados da unidade EXECUTANTE\n",
    "dfMarcacao = pd.merge(\n",
    "    dfMarcacao,\n",
    "    unidades[['unidade_id_cnes', 'unidade_bairro', 'unidade_latitude', 'unidade_longitude']],\n",
    "    left_on='unidade_executante_id_cnes',\n",
    "    right_on='unidade_id_cnes',\n",
    "    how='left',\n",
    "    suffixes=('_solicitante', '_executante')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72719ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Função para calcular a Distância de Haversine (distância em linha reta na Terra)\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Raio da Terra em km\n",
    "    \n",
    "    lat1_rad = np.radians(lat1)\n",
    "    lon1_rad = np.radians(lon1)\n",
    "    lat2_rad = np.radians(lat2)\n",
    "    lon2_rad = np.radians(lon2)\n",
    "    \n",
    "    dlon = lon2_rad - lon1_rad\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    \n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    \n",
    "    distance = R * c\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68995f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Feature de Distância\n",
    "dfMarcacao['distancia_km'] = haversine_distance(\n",
    "    dfMarcacao['unidade_latitude_solicitante'],\n",
    "    dfMarcacao['unidade_longitude_solicitante'],\n",
    "    dfMarcacao['unidade_latitude_executante'],\n",
    "    dfMarcacao['unidade_longitude_executante']\n",
    ")\n",
    "\n",
    "# 5. Feature Mesmo Bairro\n",
    "dfMarcacao['mesmo_bairro'] = (dfMarcacao['unidade_bairro_solicitante'] == dfMarcacao['unidade_bairro_executante']).astype(int)\n",
    "\n",
    "print(\"Atributos geográficos criados: 'distancia_km', 'mesmo_bairro'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f8691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- D. Fatores Clínicos e do Procedimento ---\n",
    "print(\"\\n--- Iniciando Engenharia de Atributos Clínicos (D) ---\")\n",
    "# Risco (solicitacao_risco) e Tipo de Vaga (vaga_consumida_tp) já existem.\n",
    "\n",
    "dfProcedimento = carregar_dataframe_particionado(caminho_para_pasta, 'procedimento')\n",
    "dfCids = carregar_dataframe_particionado(caminho_para_pasta, 'cids')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62adc992",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e3dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supondo que dfProcedimento e dfCids estão carregados\n",
    "# 1. Join com a tabela de Procedimentos\n",
    "dfMarcacao = pd.merge(\n",
    "    dfMarcacao,\n",
    "    dfProcedimento[['procedimento_sisreg_id', 'procedimento_especialidade']],\n",
    "    on='procedimento_sisreg_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 2. Join com a tabela de CID\n",
    "dfMarcacao = pd.merge(\n",
    "    dfMarcacao,\n",
    "    dfCids[['cid_id', 'cid']], # Pegando a categoria do CID\n",
    "    left_on='cid_agendado_id',\n",
    "    right_on='cid_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(\"Atributos clínicos adicionados: 'procedimento_especialidade', 'cid_categoria_descricao'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e6496e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Limpeza Final ---\n",
    "# Remover colunas de ID e geográficas que não são mais necessárias para o modelo\n",
    "colunas_para_remover = [\n",
    "    'unidade_id_cnes_solicitante', 'unidade_bairro_solicitante', 'unidade_latitude_solicitante', 'unidade_longitude_solicitante',\n",
    "    'unidade_id_cnes_executante', 'unidade_bairro_executante', 'unidade_latitude_executante', 'unidade_longitude_executante',\n",
    "    'cid_id'\n",
    "]\n",
    "dfMarcacao.drop(columns=colunas_para_remover, inplace=True, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fc7d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando as novas colunas\n",
    "novas_colunas = [\n",
    "    'lead_time_dias', 'dia_semana', 'hora_dia', 'mes',\n",
    "    'num_agendamentos_anteriores', 'taxa_absenteismo_anterior',\n",
    "    'distancia_km', 'mesmo_bairro',\n",
    "    'procedimento_especialidade', 'cid', 'alvo_absenteismo'\n",
    "]\n",
    "print(\"\\nAmostra do DataFrame final com as novas features:\")\n",
    "print(dfMarcacao[novas_colunas].head())\n",
    "\n",
    "print(\"\\nInformações sobre as novas colunas (verificar nulos):\")\n",
    "print(dfMarcacao[novas_colunas].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aac8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c17f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supondo que 'df_modelagem' é o DataFrame final da etapa de Engenharia de Atributos\n",
    "# Certifique-se de que a coluna de data de marcação está no formato datetime\n",
    "dfMarcacao['data_marcacao'] = pd.to_datetime(dfMarcacao['data_marcacao'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85202a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar as features (X) e o alvo (y)\n",
    "# Vamos excluir colunas de ID, datas e texto livre que não serão usadas diretamente\n",
    "features_para_usar = [\n",
    "    'lead_time_dias', 'dia_semana', 'hora_dia', 'mes', \n",
    "    'num_agendamentos_anteriores', 'taxa_absenteismo_anterior',\n",
    "    'distancia_km', 'mesmo_bairro', 'paciente_sexo', 'paciente_faixa_etaria',\n",
    "    'paciente_avisado', 'solicitacao_risco', 'vaga_consumida_tp',\n",
    "    'procedimento_especialidade', 'cid'\n",
    "]\n",
    "alvo = 'alvo_absenteismo'\n",
    "\n",
    "X = dfMarcacao[features_para_usar]\n",
    "y = dfMarcacao[alvo]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f92550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar colunas numéricas e categóricas automaticamente\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64', 'int32']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
    "\n",
    "print(\"--- Variáveis Definidas ---\")\n",
    "print(f\"Features numéricas: {numerical_features}\")\n",
    "print(f\"Features categóricas: {categorical_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ca567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Passo 2: Divisão Temporal dos Dados ---\n",
    "\n",
    "# Ordenar os dados por data para garantir uma divisão temporal correta\n",
    "df_modelagem_sorted = dfMarcacao.sort_values('data_marcacao')\n",
    "\n",
    "# Definir um ponto de corte (ex: 80% dos dados para treino, 20% para teste)\n",
    "split_point = int(len(df_modelagem_sorted) * 0.8)\n",
    "train_df = df_modelagem_sorted.iloc[:split_point]\n",
    "test_df = df_modelagem_sorted.iloc[split_point:]\n",
    "\n",
    "X_train = train_df[features_para_usar]\n",
    "y_train = train_df[alvo]\n",
    "X_test = test_df[features_para_usar]\n",
    "y_test = test_df[alvo]\n",
    "\n",
    "print(f\"\\n--- Divisão Temporal ---\")\n",
    "print(f\"Dados de treino: {len(X_train):,} linhas, de {train_df['data_marcacao'].min():%Y-%m-%d} a {train_df['data_marcacao'].max():%Y-%m-%d}\")\n",
    "print(f\"Dados de teste: {len(X_test):,} linhas, de {test_df['data_marcacao'].min():%Y-%m-%d} a {test_df['data_marcacao'].max():%Y-%m-%d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43019b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um pipeline de pré-processamento para o modelo\n",
    "# Para features numéricas: preencher valores nulos com a mediana e escalar\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Para features categóricas: preencher nulos com 'missing' e aplicar One-Hot Encoding\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "# Juntar os pré-processadores\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Criar o pipeline final que inclui o pré-processamento e o modelo\n",
    "lr_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('classifier', LogisticRegression(random_state=42, solver='liblinear'))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9281f6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Código de Diagnóstico ---\n",
    "print(\"\\n--- Verificando a distribuição do alvo nos conjuntos ---\")\n",
    "print(\"Distribuição em y_train:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print(\"\\nDistribuição em y_test:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaef848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NOVO DIAGNÓSTICO: Investigar as colunas-fonte em dfMarcacao ---\n",
    "\n",
    "print(\"--- Investigando as colunas originais em dfMarcacao ---\")\n",
    "\n",
    "print(\"\\nValores únicos e contagem na coluna 'marcacao_executada':\")\n",
    "# O dropna=False nos mostrará se existem valores nulos (NaN)\n",
    "print(dfMarcacao['marcacao_executada'].value_counts(dropna=False))\n",
    "\n",
    "print(\"\\n----------------------------------------------------\")\n",
    "\n",
    "print(\"\\nValores únicos e contagem na coluna 'falta_registrada':\")\n",
    "print(dfMarcacao['falta_registrada'].value_counts(dropna=False))\n",
    "\n",
    "print(\"\\n----------------------------------------------------\")\n",
    "\n",
    "print(\"\\nValores únicos e contagem na coluna 'solicitacao_status' (Top 15):\")\n",
    "# Esta coluna é nossa melhor candidata para encontrar o status de falta\n",
    "print(dfMarcacao['solicitacao_status'].value_counts(dropna=False).head(15))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
